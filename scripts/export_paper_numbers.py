#!/usr/bin/env python3
"""
export_paper_numbers.py

Single source of truth exporter for paper constants.

Reads diffusion CSVs from data/generated/ and exports:
  - outputs/paper/paper_numbers.json          (lightweight, paper-grade)
  - outputs/paper/paper_numbers_full.json     (full debug/audit payload)
  - outputs/paper/paper_table_diffusion.tex

Uses the exact same fit logic as scripts/run_diffusion_analysis.py.
"""

from __future__ import annotations

import argparse
import json
import math
import re
import subprocess
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd

# Import analysis logic from your existing script
from run_diffusion_analysis import analyze_df

DEFAULT_PATTERN = r"^phase_diff_(?:omega|pure_diff).*\.csv$"

ROOT = Path(__file__).resolve().parents[1]
DATA = ROOT / "data" / "generated"
OUTP = ROOT / "outputs" / "paper"
OUTP.mkdir(parents=True, exist_ok=True)


def utc_now_iso() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


def git_info(repo_root: Path) -> Dict[str, Any]:
    def run(cmd: List[str]) -> str:
        try:
            out = subprocess.check_output(cmd, cwd=str(repo_root), stderr=subprocess.DEVNULL)
            return out.decode("utf-8", errors="replace").strip()
        except Exception:
            return ""

    commit = run(["git", "rev-parse", "HEAD"])
    dirty = (run(["git", "status", "--porcelain"]) != "")
    return {"commit": commit, "dirty": dirty}


def tex_escape(s: str) -> str:
    return (s.replace("\\", "\\textbackslash{}")
             .replace("_", "\\_")
             .replace("%", "\\%")
             .replace("&", "\\&")
             .replace("#", "\\#"))

def strip_large_fields(obj: Any, *, max_list: int = 500) -> Any:
    """
    Keep paper_numbers.json lightweight:
      - convert numpy scalars/arrays safely
      - truncate very large lists
      - drop bulky series keys if present
    """
    # numpy -> python
    try:
        import numpy as np  # optional dependency; already in your env

        if isinstance(obj, (np.floating, np.integer)):
            return obj.item()
        if isinstance(obj, np.ndarray):
            return obj.tolist()
    except Exception:
        pass

    if isinstance(obj, dict):
        drop_keys = {
            # generic bulk payload keys
            "series",
            "raw",
            "points",
            "data",
            "df",
            # common per-N arrays / series names
            "N",
            "N_delay_steps",
            "delay_steps",
            "mean_dtheta_series",
            "var_dtheta_series",
            "coherence_mag_series",
            "variance_series",
            "coherence_series",
        }
        out: Dict[str, Any] = {}
        for k, v in obj.items():
            if k in drop_keys:
                continue
            out[k] = strip_large_fields(v, max_list=max_list)
        return out

    if isinstance(obj, list):
        if len(obj) > max_list:
            return obj[:max_list] + [{"__truncated__": len(obj) - max_list}]
        return [strip_large_fields(x, max_list=max_list) for x in obj]

    return obj


def find_diffusion_csvs(data_dir: Path, pattern: Optional[str]) -> List[Path]:
    csvs = sorted(data_dir.glob("*.csv"))
    if pattern:
        rx = re.compile(pattern)
        csvs = [p for p in csvs if rx.search(p.name)]
    return csvs


def parse_sigma_N_from_name(name: str) -> tuple[float | None, int | None, str]:
    """
    Examples:
      phase_diff_omega_sigma_0p2_N200.csv        -> sigma=0.2, N=200, tag=""
      phase_diff_omega_sigma_0p1_N30_dense.csv   -> sigma=0.1, N=30,  tag="dense"
      phase_diff_pure_diff_N50.csv               -> sigma=None, N=50, tag=""
    """
    sigma = None
    N = None
    tag = ""

    m = re.search(r"sigma_([0-9]+p[0-9]+)", name)
    if m:
        sigma = float(m.group(1).replace("p", "."))

    m = re.search(r"_N([0-9]+)", name)
    if m:
        N = int(m.group(1))

    if "_dense" in name:
        tag = "dense"

    return sigma, N, tag


def write_table_tex(path: Path, rows: List[Dict[str, Any]]) -> None:
    lines: List[str] = []
    lines.append("% Auto-generated by scripts/export_paper_numbers.py. Do not edit.\n")
    lines.append("\\begin{tabular}{l r r l r r r}\n")
    lines.append("\\hline\n")
    lines.append(
        "Mode & $\\sigma$ & $N$ & Tag & $b$ (mixed var) & $\\alpha$ & $\\beta$ [N$_{\\rm used}$]\\\\\n"
    )
    lines.append("\\hline\n")

    def fmt_num(x: Any) -> str:
        if x is None:
            return "--"
        try:
            xf = float(x)
        except Exception:
            return "--"
        if math.isnan(xf):
            return "--"
        return f"{xf:.6g}"

    def fmt_tag(t: Any) -> str:
        return (t or "")

    for r in rows:
        beta_cell = fmt_num(r.get("beta"))
        n_used = r.get("n_used")
        if n_used is not None and r.get("beta") is not None:
            beta_cell = f"{beta_cell}~[{int(n_used)}]"

        mode_cell = r"\texttt{" + tex_escape(str(r.get("mode",""))) + "}"
        tag_cell  = r"\texttt{" + tex_escape(str(fmt_tag(r.get("tag")))) + "}"

        lines.append(
            f"{mode_cell} & {fmt_num(r.get('sigma'))} & {int(r['N'])} & {tag_cell} & "
            f"{fmt_num(r.get('b'))} & {fmt_num(r.get('alpha'))} & {beta_cell}\\\\\n"
        )

    lines.append("\\hline\n")
    lines.append("\\end{tabular}\n")
    path.write_text("".join(lines), encoding="utf-8")


def _mode_from_stem(stem: str) -> str:
    if "phase_diff_omega" in stem:
        return "omega"
    if "phase_diff_pure_diff" in stem:
        return "pure_diff"
    return "other"


def _sigma_key(sigma: float | None) -> float:
    # stable dedupe key: use -1 for None (pure_diff)
    return float(sigma) if sigma is not None else -1.0


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--pattern", default=DEFAULT_PATTERN, help="regex to filter diffusion CSV filenames")
    ap.add_argument("--c-min", type=float, default=2e-2, help="coherence threshold for fits")
    ap.add_argument("--max-N", type=int, default=None, help="max N for coherence fits (optional)")
    ap.add_argument(
        "--strict",
        action="store_true",
        help="fail if mixed coherence beta < 0 or not enough points",
    )
    ap.add_argument(
        "--strip-max-list",
        type=int,
        default=500,
        help="max list length to keep in paper_numbers.json (default: 500)",
    )
    args = ap.parse_args()

    csvs = find_diffusion_csvs(DATA, args.pattern)
    if not csvs:
        raise SystemExit(f"No CSVs found in {DATA} (pattern={args.pattern!r})")

    results: Dict[str, Any] = {
        "generated_utc": utc_now_iso(),
        "git": git_info(ROOT),
        "inputs": {
            "pattern": args.pattern,
            "c_min": args.c_min,
            "max_N": args.max_N,
        },
        "diffusion": {},
    }

    # Dedupe table rows by (mode, sigma, N) and prefer tag="dense"
    table_best: Dict[Tuple[str, float, int], Dict[str, Any]] = {}
    failures: List[str] = []

    for p in csvs:
        try:
            df = pd.read_csv(p)
        except Exception as e:
            failures.append(f"{p.name}: read failed: {e}")
            continue

        try:
            out = analyze_df(df, c_min=args.c_min, max_N=args.max_N)
        except Exception as e:
            failures.append(f"{p.name}: analyze failed: {e}")
            continue

        stem = p.stem
        mode = _mode_from_stem(stem)

        sigma, N_from_name, tag = parse_sigma_N_from_name(p.name)

        # Prefer N from analysis output (trust the CSV), fallback to name.
        N_data = int(out["N_max"]) if out.get("N_max") is not None else None
        N = N_data if N_data is not None else (N_from_name or -1)

        sigma_str = f"{sigma:.2f}" if sigma is not None else "NA"
        tag_str = f"_{tag}" if tag else ""
        key = f"{mode}_sigma_{sigma_str}_N{N}{tag_str}"

        # Prefer "dense" entry for same (mode, sigma, N) in JSON too.
        skey = _sigma_key(sigma)
        dedupe_key = (mode, skey, int(N))

        entry = {
            "file": str(p.relative_to(ROOT)),
            "sigma": sigma,
            "N": N,
            "tag": tag,
            "analysis": out,
        }

        prev_k = results["diffusion"].get(key)
        if prev_k is None:
            # Check if any existing entry matches (mode, sigma, N) regardless of key name
            existing_key = None
            existing_entry = None
            for k_existing, v_existing in results["diffusion"].items():
                if (
                    _mode_from_stem(k_existing) == mode
                    and int(v_existing.get("N", -999999)) == int(N)
                    and _sigma_key(v_existing.get("sigma")) == skey
                ):
                    existing_key = k_existing
                    existing_entry = v_existing
                    break

            if existing_entry is None:
                results["diffusion"][key] = entry
            else:
                # Replace only if new is dense and old is not
                old_tag = (existing_entry.get("tag") or "")
                new_tag = (tag or "")
                if old_tag != "dense" and new_tag == "dense":
                    del results["diffusion"][existing_key]
                    results["diffusion"][key] = entry
        else:
            results["diffusion"][key] = entry

        var_mix = out["variance"]["mixed"]   # dict with a,b,c,metrics
        coh_mix = out["coherence"]["mixed"]  # dict or None

        alpha = None
        beta = None
        n_used = None
        if coh_mix is not None:
            alpha = coh_mix.get("alpha")
            beta = coh_mix.get("beta")
            n_used = coh_mix.get("N_used")

        row = {
            "mode": mode,
            "sigma": sigma if sigma is not None else float("nan"),
            "N": N,
            "tag": tag,
            "b": var_mix.get("b"),
            "alpha": alpha,
            "beta": beta,
            "n_used": n_used,
        }

        if args.strict:
            if coh_mix is None:
                failures.append(f"{p.name}: coherence mixed fit unavailable (too few points?)")
            else:
                if beta is None:
                    failures.append(f"{p.name}: coherence mixed beta missing")
                elif beta < 0:
                    failures.append(f"{p.name}: mixed coherence beta<0 ({beta})")

        prev = table_best.get(dedupe_key)
        if prev is None:
            table_best[dedupe_key] = row
        else:
            prev_tag = (prev.get("tag") or "")
            new_tag = (row.get("tag") or "")
            if prev_tag != "dense" and new_tag == "dense":
                table_best[dedupe_key] = row

    # Write full debug/audit payload
    (OUTP / "paper_numbers_full.json").write_text(
        json.dumps(results, indent=2, sort_keys=True),
        encoding="utf-8",
    )

    # Write stripped (paper-grade) payload
    stripped = strip_large_fields(results, max_list=args.strip_max_list)
    (OUTP / "paper_numbers.json").write_text(
        json.dumps(stripped, indent=2, sort_keys=True),
        encoding="utf-8",
    )

    table_rows = list(table_best.values())
    table_rows.sort(
        key=lambda r: (
            r["mode"],
            float(r["sigma"]) if not math.isnan(float(r["sigma"])) else 1e9,
            int(r["N"]),
            (r.get("tag") or ""),
        )
    )
    write_table_tex(OUTP / "paper_table_diffusion.tex", table_rows)

    if failures:
        msg = "EXPORT FAILURES:\n" + "\n".join("  - " + f for f in failures) + "\n"
        (OUTP / "paper_numbers_failures.txt").write_text(msg, encoding="utf-8")
        print(msg)
        return 2

    print(f"[export_paper_numbers] Wrote: {OUTP/'paper_numbers.json'}")
    print(f"[export_paper_numbers] Wrote: {OUTP/'paper_numbers_full.json'}")
    print(f"[export_paper_numbers] Wrote: {OUTP/'paper_table_diffusion.tex'}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())